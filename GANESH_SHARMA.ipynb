{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANESH_SHARMA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Environment setup\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6lqEAB45mnAs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wkCwbKFv8SzY"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "AQcZWSzHkhem"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf spark-3.2.1-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "lwMqg6QE90xx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "d8c44Wyh908z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install the sqlite jdbc\n",
        "!wget -q https://repo1.maven.org/maven2/org/xerial/sqlite-jdbc/3.36.0.3/sqlite-jdbc-3.36.0.3.jar -P /content/spark-3.2.1-bin-hadoop2.7/jars"
      ],
      "metadata": {
        "id": "UUFXwsFpH57d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Importing the Essential Libraries"
      ],
      "metadata": {
        "id": "R08v-XTLdsoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "B44RQUfK-BQe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql.functions import lit, array_remove\n",
        "\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import psutil \n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "TK0Cwb9q_ZAR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# connecting to the SQLITE JDBC DRIVER\n",
        "from pyspark.sql import SparkSession\n",
        "spark = (SparkSession\n",
        " .builder\n",
        " .appName(\"IPL_MATCHES\")\n",
        " .config(\"/content/spark-3.2.1-bin-hadoop2.7/jars\", \"sqlite-jdbc-3.36.0.3.jar\")\n",
        " .getOrCreate())"
      ],
      "metadata": {
        "id": "PIzyKY2TOpvs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the datasets\n",
        "ipl_matches_pd = pd.read_csv(\"/content/ipl_matches.csv\")\n",
        "ipl_venue_pd = pd.read_csv(\"/content/ipl_venue.csv\")\n",
        "ipl_ball_by_ball_pd = pd.read_csv(\"/content/ipl_ball_by_ball.csv\")"
      ],
      "metadata": {
        "id": "dDd1gtby8Wyu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We cannot eliminate the 'NA' values from the dataset because\n",
        "# the NA values have meanings. It means that matches are tie and\n",
        "# therefore there is no result.\n",
        "ipl_matches_pd.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etydD2gUVuG9",
        "outputId": "464f294f-5eeb-4ea0-c09c-0336c6262823"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "match_id             0\n",
              "date                 0\n",
              "player_of_match      4\n",
              "venue_id             0\n",
              "neutral_venue        0\n",
              "team1                0\n",
              "team2                0\n",
              "toss_winner          0\n",
              "toss_decision        0\n",
              "winner               4\n",
              "result               4\n",
              "result_margin       17\n",
              "eliminator           4\n",
              "method             797\n",
              "umpire1              0\n",
              "umpire2              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ipl_venue_pd.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1GV5mzIV6YU",
        "outputId": "6733c3e6-499a-4299-8428-15d2278506e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "venue_id    0\n",
              "venue       0\n",
              "city        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Again the NA values should not be eliminated because the values\n",
        "# have meanings in this dataset.\n",
        "ipl_ball_by_ball_pd.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QV1LZrX-V_DW",
        "outputId": "1c1276f8-5778-49c3-d865-ecfd875f05b8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "match_id                 0\n",
              "inning                   0\n",
              "overs                    0\n",
              "ball                     0\n",
              "batsman                  0\n",
              "non_striker              0\n",
              "bowler                   0\n",
              "batsman_runs             0\n",
              "extra_runs               0\n",
              "total_runs               0\n",
              "non_boundary             0\n",
              "is_wicket                0\n",
              "dismissal_kind      183973\n",
              "player_dismissed    183973\n",
              "fielder             186684\n",
              "extras_type         183235\n",
              "batting_team             0\n",
              "bowling_team           191\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. ANALYZING THE DATA SET .\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "sZiObeA5mvdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Database:\n",
        "  def __init__(self):\n",
        "    # Creating a database named as info.db and at the same time extablishing a connection to the\n",
        "    # data base.\n",
        "    # Uploading the data that have been loaded through the pandas into the database info.db and later\n",
        "    # this database will be analysed using spark.\n",
        "\n",
        "    try:\n",
        "      self.connection = sqlite3.connect(\"information.db\")\n",
        "      self.crsr = self.connection.cursor()\n",
        "\n",
        "      # Loading the dataset into sql database\n",
        "      ipl_matches_pd.to_sql(\"ipl_matches\", self.connection, if_exists = 'replace', index = False)\n",
        "      ipl_venue_pd.to_sql(\"ipl_venue\", self.connection, if_exists = 'replace', index = False)\n",
        "      ipl_ball_by_ball_pd.to_sql(\"ipl_ball_by_ball\", self.connection, if_exists = 'replace', index = False)\n",
        "\n",
        "      # Connecting PySpark with the sqllite database.\n",
        "\n",
        "      self.ipl_matches = spark.read.format(\"jdbc\").option(\"url\", \"jdbc:sqlite:information.db\")\\\n",
        "                      .option(\"dbtable\", \"ipl_matches\")\\\n",
        "                      .option(\"driver\",\"org.sqlite.JDBC\")\\\n",
        "                      .option(\"user\", \"gs\")\\\n",
        "                      .option(\"password\", \"passkey\")\\\n",
        "                      .load()\n",
        "\n",
        "      self.ipl_venue = spark.read.format(\"jdbc\").option(\"url\", \"jdbc:sqlite:information.db\")\\\n",
        "                          .option(\"dbtable\", \"ipl_venue\")\\\n",
        "                          .option(\"driver\",\"org.sqlite.JDBC\")\\\n",
        "                          .option(\"user\", \"gs\")\\\n",
        "                          .option(\"password\", \"passkey\")\\\n",
        "                          .load()\n",
        "\n",
        "      self.ipl_ball_by_ball = spark.read.format(\"jdbc\").option(\"url\", \"jdbc:sqlite:information.db\")\\\n",
        "                          .option(\"dbtable\", \"ipl_ball_by_ball\")\\\n",
        "                          .option(\"driver\",\"org.sqlite.JDBC\")\\\n",
        "                          .option(\"user\", \"gs\")\\\n",
        "                          .option(\"password\", \"passkey\")\\\n",
        "                          .load()\n",
        "\n",
        "      # creating view instances of each table\n",
        "\n",
        "      self.ipl_matches.createOrReplaceTempView(\"ipl_matches_view\")\n",
        "      self.ipl_venue.createOrReplaceTempView(\"ipl_venue_view\")\n",
        "      self.ipl_ball_by_ball.createOrReplaceTempView(\"ipl_ball_by_ball_view\")\n",
        "\n",
        "    except:\n",
        "      print(\"Error: Error generated in constructor space. Make sure that name of the \\\n",
        "      database file is correct, or make sure that the SQLite JDBC driver is available.\")\n",
        "\n",
        "  def player_of_the_match_awards(self):\n",
        "    \"\"\" A query to return a report for the cricketers with the most number\n",
        "     of players of the match award\"\"\"\n",
        "\n",
        "    self.ipl_man_of_the_matches = spark.sql(\"\\\n",
        "    SELECT player_of_match, COUNT(player_of_match) AS num_man_of_the_matches\\\n",
        "    FROM ipl_matches_view\\\n",
        "    GROUP BY player_of_match\\\n",
        "    ORDER BY num_man_of_the_matches DESC\\\n",
        "    LIMIT 10\")\n",
        "\n",
        "    self.show_result(self.ipl_man_of_the_matches)\n",
        "\n",
        "  def catches_per_player(self):\n",
        "    \"\"\"Most number of catches taken by a player in IPL history\"\"\"\n",
        "\n",
        "    self.fielders = spark.sql(\"\\\n",
        "      SELECT match_id, fielder\\\n",
        "      FROM ipl_ball_by_ball_view\\\n",
        "      WHERE dismissal_kind == 'caught'\")\n",
        "    \n",
        "    self.fielders = self.fielders.groupBy('fielder')\\\n",
        "    .agg({'fielder': 'count'})\\\n",
        "    .toDF('fielder', 'num_of_catches')\n",
        "\n",
        "    self.fielders.createOrReplaceTempView(\"num_of_catches\")\n",
        "\n",
        "    self.num_of_catches = spark.sql(\"\\\n",
        "      SELECT * FROM num_of_catches\\\n",
        "      ORDER BY num_of_catches DESC\\\n",
        "      LIMIT 10\")\n",
        "\n",
        "    self.show_result(self.num_of_catches)\n",
        "\n",
        "  def venues_and_matches(self):\n",
        "    \"\"\"Top 10 venues which hosted the most number of matches.\"\"\"\n",
        "\n",
        "    self.eliminator_venue_id = spark.sql(\"\\\n",
        "      SELECT venue_id FROM ipl_matches_view\")\n",
        "    \n",
        "    self.venue_view = spark.sql(\"SELECT * FROM ipl_venue_view\")\n",
        "\n",
        "    # inner joining the relation table venue with eliminator_venue_id\n",
        "    self.inner_joining = self.eliminator_venue_id\\\n",
        "    .join(self.venue_view, self.eliminator_venue_id.venue_id == self.venue_view.venue_id,\"inner\")\\\n",
        "    .drop(self.venue_view.venue_id)\n",
        "\n",
        "    self.inner_joining.createOrReplaceTempView(\"stadium_as_venue\")\n",
        "\n",
        "    self.stadium_as_venue = spark.sql(\"\\\n",
        "      SELECT venue, COUNT(venue) AS num_of_matches\\\n",
        "      FROM stadium_as_venue\\\n",
        "      GROUP BY venue\\\n",
        "      ORDER BY num_of_matches desc\\\n",
        "      LIMIT 10\")\n",
        "    \n",
        "    print(\"Stadium as a venue.\")\n",
        "    self.show_result(self.stadium_as_venue)\n",
        "\n",
        "    self.num_of_matches_per_city = self.venue_view.groupBy('city').agg({'city': 'count'})\\\n",
        "    .toDF('city', 'num_of_matches')\n",
        "\n",
        "    self.num_of_matches_per_city.createOrReplaceTempView(\"cities_as_venue\")\n",
        "    self.city_as_venue = spark.sql(\"\\\n",
        "      SELECT city, num_of_matches FROM cities_as_venue\\\n",
        "      ORDER BY num_of_matches desc\\\n",
        "      LIMIT 10\")\n",
        "    \n",
        "    print(\"City as a venue.\")\n",
        "    self.show_result(self.city_as_venue)\n",
        "\n",
        "\n",
        "  def wickets_through_dl_method(self):\n",
        "    \"\"\"query to return a report for highest wicket taker in matches \n",
        "    which were affected by Duckworth-Lewis’s method (D/L method).\"\"\"\n",
        "\n",
        "    self.dl_matches_id = spark.sql(\"\\\n",
        "      select match_id FROM ipl_matches_view\\\n",
        "      WHERE method = 'D/L'\")\n",
        "\n",
        "    self.ipl_most_wickets = spark.sql(\"\\\n",
        "      SELECT match_id, bowler, is_wicket\\\n",
        "      FROM ipl_ball_by_ball_view\\\n",
        "      WHERE is_wicket == 1\")\n",
        "    \n",
        "    # Inner joinning matches that are effected by D/L and \n",
        "    self.max_wickets = self.dl_matches_id\\\n",
        "    .join(self.ipl_most_wickets, self.dl_matches_id.match_id == self.ipl_most_wickets.match_id,\"inner\")\\\n",
        "    .drop(self.ipl_most_wickets.match_id)\n",
        "\n",
        "    self.max_wickets = self.max_wickets.groupBy('bowler').agg({'bowler': 'count'})\\\n",
        "    .toDF('bowler', 'num_of_wickets')\n",
        "\n",
        "    self.max_wickets.createOrReplaceTempView(\"max_wickets\")\n",
        "    self.max_wickets = spark.sql(\"\\\n",
        "    select * from max_wickets\\\n",
        "    ORDER BY num_of_wickets DESC LIMIT 10\")\n",
        "\n",
        "    self.show_result(self.max_wickets)\n",
        "\n",
        "  def strike_rate_in_non_powerplay_overs(self):\n",
        "    \"\"\" A query to return a report for highest strike rate by \n",
        "    the batsmans in non powerplay overs(7-20 overs)\"\"\"\n",
        "\n",
        "    self.ipl_strike_rate = spark.sql(\"\\\n",
        "    SELECT batsman, COUNT(batsman) AS total_balls, SUM(batsman_runs) AS batsman_runs\\\n",
        "    FROM ipl_ball_by_ball_view\\\n",
        "    WHERE overs BETWEEN 7 AND 20\\\n",
        "    GROUP BY batsman\")\n",
        "\n",
        "    self.ipl_strike_rate.createOrReplaceTempView(\"ipl_strike_rate\")\n",
        "    self.ipl_strike_rate = spark.sql(\"\\\n",
        "    SELECT batsman, CAST(((batsman_runs / total_balls) * 100) AS decimal(16, 2)) \\\n",
        "    AS strike_rate FROM ipl_strike_rate\\\n",
        "    ORDER BY strike_rate DESC\\\n",
        "    LIMIT 10\")\n",
        "    self.show_result(self.ipl_strike_rate)\n",
        "\n",
        "\n",
        "  def highest_batting_average(self):\n",
        "    \"\"\"A query to get a list of top 10 players with the highest batting average.\"\"\"\n",
        "\n",
        "    self.batting_player = spark.sql(\"\\\n",
        "      SELECT batsman, count(batsman) as num_of_times_out\\\n",
        "      FROM ipl_ball_by_ball_view\\\n",
        "      WHERE batsman == player_dismissed\\\n",
        "      GROUP BY batsman\")\n",
        "\n",
        "    self.non_strike_player = spark.sql(\"\\\n",
        "      SELECT non_striker, count(non_striker) AS num_of_run_outs\\\n",
        "      FROM ipl_ball_by_ball_view\\\n",
        "      WHERE non_striker == player_dismissed\\\n",
        "      GROUP by non_striker\")\n",
        "\n",
        "    self.num_of_outs_per_player = self.batting_player.union(self.non_strike_player)\n",
        "\n",
        "    self.num_of_outs_per_player.createOrReplaceTempView(\"num_of_outs\")\n",
        "    self.num_of_outs_per_player = spark.sql(\"\\\n",
        "      SELECT batsman, SUM(num_of_times_out) AS num_of_times_out\\\n",
        "      FROM num_of_outs\\\n",
        "      GROUP BY batsman\")\n",
        "\n",
        "    self.players_total_score = spark.sql(\"\\\n",
        "      SELECT batsman, sum(batsman_runs) AS runs\\\n",
        "      FROM ipl_ball_by_ball_view\\\n",
        "      GROUP BY batsman\")\n",
        "\n",
        "    self.players_total_score = self.players_total_score\\\n",
        "    .join(self.num_of_outs_per_player, self.players_total_score.batsman\\\n",
        "          == self.num_of_outs_per_player.batsman,\"inner\").drop(self.num_of_outs_per_player.batsman)\n",
        "\n",
        "    self.players_total_score.createOrReplaceTempView(\"players_total_score\")\n",
        "    self.players_total_score = spark.sql(\"\\\n",
        "      SELECT batsman, CAST((runs / num_of_times_out) AS decimal(16, 2)) AS batting_average\\\n",
        "      FROM players_total_score\\\n",
        "      ORDER BY batting_average DESC\\\n",
        "      LIMIT 10\")\n",
        "    \n",
        "    self.show_result(self.players_total_score)\n",
        "\n",
        "  def umpires_in_matches(self):\n",
        "    \"\"\"a query to find out the number of apperances of umpires in IPL matches.\"\"\"\n",
        "\n",
        "    self.umpire1 = self.ipl_matches.select('umpire1')\n",
        "    self.umpire2 = self.ipl_matches.select('umpire2')\n",
        "    self.umpires = self.umpire1.union(self.umpire2)\n",
        "    self.umpires.createOrReplaceTempView(\"all_umpires\")\n",
        "\n",
        "    self.umpires = spark.sql(\"\\\n",
        "    SELECT umpire1 AS umpires, COUNT(umpire1) AS num_of_matches\\\n",
        "    FROM all_umpires\\\n",
        "    GROUP BY umpire1\\\n",
        "    ORDER BY num_of_matches DESC\\\n",
        "    LIMIT 10\")\n",
        "\n",
        "    self.show_result(self.umpires)\n",
        "\n",
        "\n",
        "  def show_result(self, getInput):\n",
        "    getInput.show()"
      ],
      "metadata": {
        "id": "0zCvvi41n8R-"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating instance of database\n",
        "database_instance = Database()"
      ],
      "metadata": {
        "id": "X4QfGARjlIJU"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of catches taken by each player.\n",
        "database_instance.catches_per_player()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ak8Td9UBmiTk",
        "outputId": "0c20b513-11f3-4094-e2da-8cb23883a960"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------------+\n",
            "|       fielder|num_of_catches|\n",
            "+--------------+--------------+\n",
            "|    KD Karthik|           118|\n",
            "|      MS Dhoni|           113|\n",
            "|AB de Villiers|           103|\n",
            "|      SK Raina|            99|\n",
            "|     RG Sharma|            88|\n",
            "|    RV Uthappa|            87|\n",
            "|    KA Pollard|            84|\n",
            "|       V Kohli|            76|\n",
            "|      S Dhawan|            73|\n",
            "|     MK Pandey|            70|\n",
            "+--------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 strike rate of the batsman.\n",
        "database_instance.strike_rate_in_non_powerplay_overs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-qzHo_8miXs",
        "outputId": "03d3fdcf-a8df-417d-c5cc-86898679673b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "|     batsman|strike_rate|\n",
            "+------------+-----------+\n",
            "|  B Stanlake|     250.00|\n",
            "|Kamran Akmal|     213.89|\n",
            "|  ER Dwivedi|     211.11|\n",
            "|    Umar Gul|     205.26|\n",
            "|    RS Sodhi|     200.00|\n",
            "| AC Blizzard|     200.00|\n",
            "|   DJM Short|     187.10|\n",
            "|   LJ Wright|     183.02|\n",
            "|    W Jaffer|     180.77|\n",
            "|Vishnu Vinod|     180.00|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Highest batting average\n",
        "database_instance.highest_batting_average()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txE3cwdnmikx",
        "outputId": "9ae4442b-9d39-47c0-a6c9-46ae07f7f9b7"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+\n",
            "|      batsman|batting_average|\n",
            "+-------------+---------------+\n",
            "|   MN van Wyk|          55.67|\n",
            "|   RD Gaikwad|          51.00|\n",
            "|     AC Voges|          45.25|\n",
            "|     KL Rahul|          44.86|\n",
            "|      HM Amla|          44.38|\n",
            "|Iqbal Abdulla|          44.00|\n",
            "|    DA Warner|          42.72|\n",
            "|  JM Bairstow|          41.58|\n",
            "|     CH Gayle|          41.14|\n",
            "|     MS Dhoni|          40.99|\n",
            "+-------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of matches per venue.\n",
        "database_instance.venues_and_matches()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMCqOE63eYcp",
        "outputId": "84831473-13b6-4964-ab03-64b686010c8c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stadium as a venue.\n",
            "+--------------------+--------------+\n",
            "|               venue|num_of_matches|\n",
            "+--------------------+--------------+\n",
            "|M.Chinnaswamy Sta...|            80|\n",
            "|        Eden Gardens|            77|\n",
            "|    Feroz Shah Kotla|            74|\n",
            "|    Wankhede Stadium|            73|\n",
            "|Rajiv Gandhi Inte...|            64|\n",
            "|MA Chidambaram St...|            57|\n",
            "|Sawai Mansingh St...|            47|\n",
            "|Punjab Cricket As...|            35|\n",
            "|Dubai Internation...|            33|\n",
            "|Sheikh Zayed Stadium|            29|\n",
            "+--------------------+--------------+\n",
            "\n",
            "City as a venue.\n",
            "+----------+--------------+\n",
            "|      city|num_of_matches|\n",
            "+----------+--------------+\n",
            "|    Mumbai|             3|\n",
            "|      Pune|             2|\n",
            "|Chandigarh|             2|\n",
            "|     Kochi|             1|\n",
            "|   Chennai|             1|\n",
            "| Centurion|             1|\n",
            "|    Ranchi|             1|\n",
            "| Ahmedabad|             1|\n",
            "|    Durban|             1|\n",
            "|   Kolkata|             1|\n",
            "+----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of wickets per bowler\n",
        "database_instance.wickets_through_dl_method()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emBjMfkndXAX",
        "outputId": "e1aed38e-3b3d-4213-8901-d944c1afce1b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------------+\n",
            "|      bowler|num_of_wickets|\n",
            "+------------+--------------+\n",
            "|    R Ashwin|             8|\n",
            "|    AB Dinda|             8|\n",
            "|MC Henriques|             7|\n",
            "|     B Kumar|             6|\n",
            "|  JD Unadkat|             5|\n",
            "|    L Balaji|             5|\n",
            "|    TA Boult|             5|\n",
            "|  DL Vettori|             5|\n",
            "|   YS Chahal|             4|\n",
            "|     M Ntini|             4|\n",
            "+------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Player of the match awards per player\n",
        "database_instance.player_of_the_match_awards()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWbKCXZ9geE7",
        "outputId": "6b1e8cf7-59a0-4abb-bca9-802bfd25f0d1"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----------------------+\n",
            "|player_of_match|num_man_of_the_matches|\n",
            "+---------------+----------------------+\n",
            "| AB de Villiers|                    23|\n",
            "|       CH Gayle|                    22|\n",
            "|      RG Sharma|                    18|\n",
            "|      DA Warner|                    17|\n",
            "|       MS Dhoni|                    17|\n",
            "|      YK Pathan|                    16|\n",
            "|      SR Watson|                    16|\n",
            "|       SK Raina|                    14|\n",
            "|      G Gambhir|                    13|\n",
            "|        V Kohli|                    13|\n",
            "+---------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Most number of umpires participate in the matches.\n",
        "database_instance.umpires_in_matches()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf0oaB0XgpLJ",
        "outputId": "47f5ff62-4851-410b-8573-7fbf481b95d6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------+\n",
            "|        umpires|num_of_matches|\n",
            "+---------------+--------------+\n",
            "|         S Ravi|           121|\n",
            "|HDPK Dharmasena|            94|\n",
            "|   AK Chaudhary|            87|\n",
            "|  C Shamshuddin|            82|\n",
            "|      M Erasmus|            65|\n",
            "|      CK Nandan|            57|\n",
            "|    Nitin Menon|            57|\n",
            "|     SJA Taufel|            55|\n",
            "|      Asad Rauf|            51|\n",
            "|    VA Kulkarni|            50|\n",
            "+---------------+--------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}